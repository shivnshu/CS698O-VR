{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: The Winter is here\n",
    "##### This works best with epic battle music. No spoilers present.\n",
    "<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tywin Lannister was right when he said: \"The great war is between death and life, ice and fire. If we loose, the night will never end\"<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It has been six months since the white walkers' army marched into the north, led by the night king himself on a dead dragon. It has been a battle like never before: never before have men faced such an enemy in battle, never before have men fought so bravely against a united threat, and never before have they been so gravely defeated.<br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; While Cersei is in King's landing, brave men have died fighting the great war. Among others, Tyrion is dead, Arya is dead and Jon Snow is dead, again. In a desperate battle, Daenerys leads all her forces in a final stand-off with the dead just south of Winterfell. <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Her army defeated, she is now on the run on her dragon in an air battle, being chased by two of her own dragons, the Night king and a dead Jon Snow. Suddenly, the Night king's spear hits Danny's dragon, who, raining blood and fire, falls into ice, taking the lost queen, with him. <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Daenerys opens her eyes in a strange place, a place which does not follow the rules of space and time, where the dead souls killed by the dead men are trapped, forever. But who woke her up? There stands near her, Tyrion, with Jorah, Davos, Jon Snow, and everybody else. They all indulge in a heartfelt reunion when someone yells- \"But how do we get out?<br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Varys sees a talking crystal close by, who asks them of completing a task, which on completion would allow them to go back to the land of the living, with the ultimate tool to defeat the white-walkers and kills the night king, the Dragon-axe. They have summoned you for help, as the task is out of their expertise, to apply a modified CNN to solve the object detection problem on the PASCAL VOC dataset. Varys, the master of whisperers, has used his talents to import the following for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()\n",
    "# You can ask Varys to get you more if you desire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_input = 224 #size of resnet18 input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cersei chose violence, you choose your hyper-parameters wisely using validation data!\n",
    "batch_size = 20\n",
    "num_epochs = 5\n",
    "learning_rate =  0.001\n",
    "hyp_momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build the data\n",
    "The hound who was in charge for getting the data, brought you the following links:\n",
    "<br/>Training and validation:\n",
    "<br/>http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "<br/>Testing data:\n",
    "<br/>http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "<br/>He also told you that the dataset(datascrolls :P) consists of images from of 20 classes, with detection annotations included. The JPEGImages folder houses the images, and the Annotations folder has the object-wise labels for the objects in one xml file per image. You have to extract the object information, ie. the [xmin, ymin] (the top left x,y co-ordinates) and the [xmax, ymax] (the bottom right x,y co-ordinates) of only the objects belonging to the given 20 classes(aeroplane, bicycle, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, train, TV). For parsing the xml file, you can ask Varys to import xml.etree.ElementTree for you. <br/>\n",
    "<br/> You can then ask Bronn and Jamie to organize the data as follows:\n",
    "<br/> For every image in the dataset, extract/crop the object patch from the image one by one using their respective co-ordinates:[xmin, ymin, xmax, ymax], resize the image to resnet_input, and store it with its class label information. Do the same for training/validation and test datasets. <br/>\n",
    "##### Important\n",
    "You also have to collect data for an extra background class which stands for the class of an object which is not a part of any of the 20 classes. For this, you can crop and resize any random patches from an image. A good idea is to extract patches that have low \"intersection over union\" with any object present in the image frame from the 20 Pascal VOC classes. The number of background images should be roughly around those of other class objects' images. Hence the total classes turn out to be 21. This is important for applying the sliding window method later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ('__background__',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "           'cow', 'diningtable', 'dog', 'horse',\n",
    "           'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "counts = [0]*21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')\n",
    "\n",
    "def area(a, b):  # returns None if rectangles don't intersect\n",
    "    dx = min(a.xmax, b.xmax) - max(a.xmin, b.xmin)\n",
    "    dy = min(a.ymax, b.ymax) - max(a.ymin, b.ymin)\n",
    "    if (dx>=0) and (dy>=0):\n",
    "        return dx*dy\n",
    "    \n",
    "ra = Rectangle(1, 1, 3, 3)\n",
    "rb = Rectangle(1, 1, 5, 5)\n",
    "\n",
    "type(area(ra,rb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_hierarchical_dirs():\n",
    "    if not os.path.exists('data/train'):\n",
    "        os.makedirs('data/train')\n",
    "        \n",
    "    for i in range(len(classes)):\n",
    "        dirname = 'data/train/' + classes[i]\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "\n",
    "create_train_hierarchical_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jamie_bronn_build_dataset():\n",
    "    \n",
    "    dir_names = os.listdir('data/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations')\n",
    "    for img_name in dir_names:\n",
    "        tree = ET.parse('data/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations/' + img_name)\n",
    "        root = tree.getroot()\n",
    "        for object1 in root.iter('object'):\n",
    "            for name1 in object1.iter('name'):\n",
    "                dirname = name1.text\n",
    "            for bndbox in object1.iter('bndbox'):\n",
    "                for xmin in object1.iter('xmin'):\n",
    "                    x1 = int(float(xmin.text))\n",
    "                for xmax in object1.iter('xmax'):\n",
    "                    x2 = int(float(xmax.text))\n",
    "                for ymin in object1.iter('ymin'):\n",
    "                    y1 = int(float(ymin.text))\n",
    "                for ymax in object1.iter('ymax'):\n",
    "                    y2 = int(float(ymax.text))\n",
    "\n",
    "                img = Image.open('data/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/' + img_name[0:-4] + '.jpg')\n",
    "                img = img.crop((x1,y1,x2,y2))\n",
    "                if dirname in classes:\n",
    "                    img.save('data/train/' + dirname + '/' + str(counts[classes.index(dirname)]) + \".jpg\");\n",
    "                    counts[classes.index(dirname)]+=1\n",
    "        \n",
    "jamie_bronn_build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "152 327 274 425\n",
      "0\n",
      "187 117 361 251\n",
      "1\n",
      "455 218 474 240\n",
      "2\n",
      "45 70 106 183\n",
      "3\n",
      "310 6 451 335\n",
      "4\n",
      "139 102 398 283\n",
      "5\n",
      "48 18 100 315\n",
      "6\n",
      "358 107 397 243\n",
      "7\n",
      "292 141 359 264\n",
      "8\n",
      "63 250 113 407\n",
      "9\n",
      "125 41 177 143\n",
      "10\n",
      "366 92 447 331\n",
      "11\n",
      "209 41 340 203\n",
      "12\n",
      "375 182 490 291\n",
      "13\n",
      "115 67 206 234\n",
      "14\n",
      "89 40 477 125\n",
      "15\n",
      "21 357 331 373\n",
      "16\n",
      "119 173 141 194\n",
      "16\n",
      "222 71 451 89\n",
      "17\n",
      "139 158 367 302\n",
      "18\n",
      "142 139 249 251\n",
      "19\n",
      "40 52 177 143\n",
      "20\n",
      "0 124 356 217\n",
      "21\n",
      "71 137 463 224\n",
      "22\n",
      "265 306 311 470\n",
      "23\n",
      "59 76 350 424\n",
      "24\n",
      "154 11 314 157\n",
      "25\n",
      "1 149 208 219\n",
      "26\n",
      "82 67 351 371\n",
      "27\n",
      "7 336 241 492\n",
      "28\n",
      "70 142 267 204\n",
      "29\n",
      "172 50 372 367\n",
      "30\n",
      "245 246 423 316\n",
      "31\n",
      "161 185 448 256\n",
      "32\n",
      "150 144 318 219\n",
      "33\n",
      "214 29 391 87\n",
      "34\n",
      "173 411 180 438\n",
      "34\n",
      "230 76 283 314\n",
      "35\n",
      "43 360 402 363\n",
      "36\n",
      "38 261 272 326\n",
      "37\n",
      "123 196 302 332\n",
      "38\n",
      "21 40 308 382\n",
      "39\n",
      "91 39 363 187\n",
      "40\n",
      "225 140 296 365\n",
      "41\n",
      "210 154 347 296\n",
      "42\n",
      "97 238 121 346\n",
      "43\n",
      "43 67 454 241\n",
      "44\n",
      "59 104 125 281\n",
      "45\n",
      "184 216 361 357\n",
      "46\n",
      "278 84 306 289\n",
      "47\n",
      "142 214 211 469\n",
      "47\n",
      "152 57 426 219\n",
      "48\n",
      "324 124 356 241\n",
      "49\n",
      "410 22 495 101\n",
      "50\n",
      "244 327 298 337\n",
      "51\n",
      "142 275 303 336\n",
      "52\n",
      "44 135 443 244\n",
      "53\n",
      "109 195 360 232\n",
      "54\n",
      "262 342 360 352\n",
      "55\n",
      "328 249 441 283\n",
      "56\n",
      "317 214 363 238\n",
      "57\n",
      "70 113 216 249\n",
      "58\n",
      "79 105 479 305\n",
      "59\n",
      "36 21 102 66\n",
      "60\n",
      "3 373 232 498\n",
      "61\n",
      "124 151 405 350\n",
      "62\n",
      "128 242 195 245\n",
      "63\n",
      "263 30 490 266\n",
      "64\n",
      "300 114 361 431\n",
      "65\n",
      "379 296 390 329\n",
      "66\n",
      "229 4 361 72\n",
      "67\n",
      "17 30 263 265\n",
      "68\n",
      "295 50 356 268\n",
      "69\n",
      "161 400 360 493\n",
      "70\n",
      "233 165 348 494\n",
      "71\n",
      "169 37 303 59\n",
      "72\n",
      "20 144 72 280\n",
      "73\n",
      "45 120 97 328\n",
      "74\n",
      "61 135 107 266\n",
      "75\n",
      "33 246 470 275\n",
      "76\n",
      "182 276 346 322\n",
      "77\n",
      "130 24 222 289\n",
      "78\n",
      "84 106 203 462\n",
      "79\n",
      "280 13 343 364\n",
      "80\n",
      "370 102 491 307\n",
      "81\n",
      "269 251 345 293\n",
      "82\n",
      "80 121 262 159\n",
      "83\n",
      "62 130 496 251\n",
      "84\n",
      "119 143 269 309\n",
      "85\n",
      "167 174 219 343\n",
      "86\n",
      "89 44 117 189\n",
      "87\n",
      "355 6 450 302\n",
      "88\n",
      "244 79 345 221\n",
      "89\n",
      "41 106 312 110\n",
      "90\n",
      "279 39 296 313\n",
      "91\n",
      "75 156 307 213\n",
      "92\n",
      "165 201 304 208\n",
      "93\n",
      "398 41 412 117\n",
      "94\n",
      "195 7 448 34\n",
      "95\n",
      "51 121 457 327\n",
      "96\n",
      "199 41 488 327\n",
      "97\n",
      "45 194 181 215\n",
      "98\n",
      "156 300 481 321\n",
      "99\n",
      "100 61 309 200\n",
      "100\n",
      "375 28 421 305\n",
      "101\n",
      "117 86 169 132\n",
      "102\n",
      "270 66 403 354\n",
      "103\n",
      "265 3 334 301\n",
      "104\n",
      "335 87 378 151\n",
      "105\n",
      "140 84 171 85\n",
      "106\n",
      "39 53 414 389\n",
      "107\n",
      "42 127 168 230\n",
      "108\n",
      "3 24 206 232\n",
      "109\n",
      "43 98 291 329\n",
      "110\n",
      "130 253 137 404\n",
      "111\n",
      "41 14 67 302\n",
      "112\n",
      "226 132 351 313\n",
      "113\n",
      "90 63 182 364\n",
      "114\n",
      "307 131 326 226\n",
      "115\n",
      "257 189 308 223\n",
      "116\n",
      "55 162 66 272\n",
      "117\n",
      "50 178 174 242\n",
      "117\n",
      "294 135 450 352\n",
      "118\n",
      "77 131 461 259\n",
      "119\n",
      "174 16 413 94\n",
      "120\n",
      "223 150 474 253\n",
      "121\n",
      "159 43 433 109\n",
      "122\n",
      "425 161 426 254\n",
      "123\n",
      "303 6 473 122\n",
      "124\n",
      "304 25 373 332\n",
      "125\n",
      "18 282 124 360\n",
      "126\n",
      "10 58 198 141\n",
      "127\n",
      "133 113 401 254\n",
      "128\n",
      "107 111 363 350\n",
      "129\n",
      "435 245 487 255\n",
      "130\n",
      "171 103 264 135\n",
      "131\n",
      "96 235 103 380\n",
      "132\n",
      "10 9 438 48\n",
      "133\n",
      "2 138 291 187\n",
      "134\n",
      "224 55 423 261\n",
      "135\n",
      "28 114 251 326\n",
      "136\n",
      "326 79 442 284\n",
      "137\n",
      "337 40 495 92\n",
      "138\n",
      "163 189 488 223\n",
      "139\n",
      "261 73 263 190\n",
      "140\n",
      "177 357 262 424\n",
      "141\n",
      "185 7 494 348\n",
      "142\n",
      "95 16 144 165\n",
      "143\n",
      "49 216 98 221\n",
      "144\n",
      "13 135 221 244\n",
      "145\n",
      "46 261 176 275\n",
      "146\n",
      "201 78 487 371\n",
      "147\n",
      "6 19 25 118\n",
      "148\n",
      "159 53 289 102\n",
      "149\n",
      "432 159 482 250\n",
      "150\n",
      "93 423 235 484\n",
      "151\n",
      "12 334 404 373\n",
      "152\n",
      "246 18 424 178\n",
      "153\n",
      "24 28 54 255\n",
      "154\n",
      "67 266 161 292\n",
      "155\n",
      "283 195 399 213\n",
      "156\n",
      "68 311 467 350\n",
      "157\n",
      "171 323 216 482\n",
      "158\n",
      "119 157 243 381\n",
      "159\n",
      "155 105 411 146\n",
      "160\n",
      "114 199 158 258\n",
      "161\n",
      "9 313 51 330\n",
      "162\n",
      "183 295 297 467\n",
      "163\n",
      "25 33 147 142\n",
      "164\n",
      "383 126 393 328\n",
      "165\n",
      "163 227 179 350\n",
      "166\n",
      "28 165 190 276\n",
      "167\n",
      "357 61 477 205\n",
      "168\n",
      "123 135 335 188\n",
      "169\n",
      "79 22 144 316\n",
      "170\n",
      "368 77 368 353\n",
      "170\n",
      "49 62 259 128\n",
      "171\n",
      "229 221 348 245\n",
      "172\n",
      "83 82 297 200\n",
      "173\n",
      "17 108 200 283\n",
      "174\n",
      "58 115 329 327\n",
      "175\n",
      "186 243 373 284\n",
      "176\n",
      "166 153 254 259\n",
      "177\n",
      "62 162 350 369\n",
      "178\n",
      "27 35 140 475\n",
      "179\n",
      "107 111 159 125\n",
      "180\n",
      "14 103 114 141\n",
      "181\n",
      "37 179 104 181\n",
      "182\n",
      "272 23 352 258\n",
      "183\n",
      "245 116 411 234\n",
      "184\n",
      "15 129 421 193\n",
      "185\n",
      "59 106 101 294\n",
      "186\n",
      "3 111 276 181\n",
      "187\n",
      "23 324 214 341\n",
      "188\n",
      "70 256 132 360\n",
      "189\n",
      "447 184 461 288\n",
      "190\n",
      "335 103 352 222\n",
      "191\n",
      "167 44 360 172\n",
      "192\n",
      "467 115 469 149\n",
      "193\n",
      "340 67 387 315\n",
      "194\n",
      "115 128 323 268\n",
      "195\n",
      "15 56 499 313\n",
      "196\n",
      "3 242 196 284\n",
      "197\n",
      "10 410 58 498\n",
      "198\n",
      "171 206 494 321\n",
      "199\n",
      "86 25 119 44\n",
      "200\n",
      "75 251 225 348\n",
      "201\n",
      "69 8 147 147\n",
      "202\n",
      "124 229 376 327\n",
      "203\n",
      "134 306 229 312\n",
      "204\n",
      "315 2 353 8\n",
      "205\n",
      "150 32 253 474\n",
      "206\n",
      "33 70 227 181\n",
      "207\n",
      "304 202 324 300\n",
      "208\n",
      "164 15 434 20\n",
      "209\n",
      "60 136 253 427\n",
      "210\n",
      "131 288 332 312\n",
      "211\n",
      "367 5 488 193\n",
      "212\n",
      "304 134 372 352\n",
      "213\n",
      "258 22 311 280\n",
      "214\n",
      "134 292 333 402\n",
      "215\n",
      "261 270 366 297\n",
      "216\n",
      "42 38 165 152\n",
      "217\n",
      "414 276 494 283\n",
      "218\n",
      "119 133 271 239\n",
      "219\n",
      "102 133 340 208\n",
      "220\n",
      "304 67 472 197\n",
      "221\n",
      "19 74 392 355\n",
      "222\n",
      "60 3 310 141\n",
      "223\n",
      "141 296 154 310\n",
      "224\n",
      "197 21 223 27\n",
      "225\n",
      "116 80 321 84\n",
      "226\n",
      "341 337 461 354\n",
      "227\n",
      "122 8 333 102\n",
      "228\n",
      "161 68 208 75\n",
      "229\n",
      "49 23 91 234\n",
      "230\n",
      "105 0 457 78\n",
      "231\n",
      "63 75 136 328\n",
      "232\n",
      "300 112 326 300\n",
      "233\n",
      "432 132 448 207\n",
      "234\n",
      "192 207 351 254\n",
      "235\n",
      "231 64 252 222\n",
      "236\n",
      "104 486 297 499\n",
      "237\n",
      "161 32 428 187\n",
      "238\n",
      "311 50 481 125\n",
      "239\n",
      "185 108 385 212\n",
      "240\n",
      "11 106 412 335\n",
      "241\n",
      "271 97 475 154\n",
      "242\n",
      "165 29 180 365\n",
      "243\n",
      "59 194 271 212\n",
      "244\n",
      "89 152 320 217\n",
      "245\n",
      "185 141 289 153\n",
      "246\n",
      "178 259 350 313\n",
      "247\n",
      "12 206 162 218\n",
      "248\n",
      "144 154 243 295\n",
      "249\n",
      "179 7 336 223\n",
      "250\n",
      "37 35 314 150\n",
      "251\n",
      "142 231 365 352\n",
      "252\n",
      "239 198 348 247\n",
      "253\n",
      "157 214 241 372\n",
      "254\n",
      "122 124 154 128\n",
      "255\n",
      "117 184 478 299\n",
      "256\n",
      "98 40 247 169\n",
      "257\n",
      "97 6 98 253\n",
      "258\n",
      "177 159 434 187\n",
      "259\n",
      "213 10 354 226\n",
      "260\n",
      "81 159 265 451\n",
      "261\n",
      "175 3 220 233\n",
      "262\n",
      "110 6 280 161\n",
      "263\n",
      "32 49 306 50\n",
      "264\n",
      "132 224 218 351\n",
      "264\n",
      "79 192 230 318\n",
      "264\n",
      "159 31 352 236\n",
      "265\n",
      "240 255 307 392\n",
      "266\n",
      "116 313 168 333\n",
      "267\n",
      "66 180 226 340\n",
      "268\n",
      "133 106 260 271\n",
      "269\n",
      "20 225 255 237\n",
      "270\n",
      "113 8 118 487\n",
      "271\n",
      "121 109 219 332\n",
      "272\n",
      "202 203 219 226\n",
      "273\n",
      "234 104 432 353\n",
      "274\n",
      "84 206 87 308\n",
      "275\n",
      "50 330 79 364\n",
      "276\n",
      "76 310 276 454\n",
      "277\n",
      "36 21 205 131\n",
      "278\n",
      "101 154 239 469\n",
      "279\n",
      "218 2 326 311\n",
      "280\n",
      "132 395 162 497\n",
      "281\n",
      "164 173 348 175\n",
      "282\n",
      "63 149 98 152\n",
      "283\n",
      "197 21 466 355\n",
      "284\n",
      "169 257 291 474\n",
      "285\n",
      "10 40 244 102\n",
      "286\n",
      "33 120 302 139\n",
      "287\n",
      "101 52 274 157\n",
      "288\n",
      "46 57 231 81\n",
      "289\n",
      "76 34 319 322\n",
      "290\n",
      "266 181 269 188\n",
      "291\n",
      "11 36 196 84\n",
      "292\n",
      "74 429 222 483\n",
      "293\n",
      "153 10 304 130\n",
      "294\n",
      "63 130 325 160\n",
      "295\n",
      "268 63 268 148\n",
      "295\n",
      "119 62 409 222\n",
      "296\n",
      "118 245 409 331\n",
      "297\n",
      "249 15 306 264\n",
      "298\n",
      "157 20 289 301\n",
      "299\n",
      "73 7 378 155\n",
      "300\n",
      "177 76 279 469\n",
      "301\n",
      "79 168 243 429\n",
      "302\n",
      "110 152 259 192\n",
      "303\n",
      "76 57 291 94\n",
      "304\n",
      "43 2 54 33\n",
      "305\n",
      "187 243 349 273\n",
      "306\n",
      "23 43 113 291\n",
      "307\n",
      "34 214 85 305\n",
      "308\n",
      "389 143 448 150\n",
      "309\n",
      "92 108 474 226\n",
      "310\n",
      "130 146 487 362\n",
      "311\n",
      "31 144 422 254\n",
      "312\n",
      "137 224 408 236\n",
      "313\n",
      "29 20 369 93\n",
      "314\n",
      "280 130 455 197\n",
      "315\n",
      "91 26 261 198\n",
      "316\n",
      "156 74 191 268\n",
      "317\n",
      "67 286 320 312\n",
      "318\n",
      "70 314 172 409\n",
      "318\n",
      "353 107 447 173\n",
      "319\n",
      "203 34 473 77\n",
      "320\n",
      "377 92 390 193\n",
      "321\n",
      "230 124 261 181\n",
      "322\n",
      "6 74 419 182\n",
      "323\n",
      "63 323 253 352\n",
      "324\n",
      "142 233 294 274\n",
      "325\n",
      "72 181 161 260\n",
      "325\n",
      "65 261 203 361\n",
      "326\n",
      "96 103 426 293\n",
      "327\n",
      "59 44 305 273\n",
      "328\n",
      "196 289 425 337\n",
      "329\n",
      "67 109 182 145\n",
      "330\n",
      "231 35 309 301\n",
      "331\n",
      "193 435 349 479\n",
      "332\n",
      "161 275 442 347\n",
      "333\n",
      "323 222 327 489\n",
      "334\n",
      "138 75 151 108\n",
      "335\n",
      "426 21 493 206\n",
      "336\n",
      "337 99 365 128\n",
      "337\n",
      "33 116 493 159\n",
      "338\n",
      "162 239 306 302\n",
      "339\n",
      "144 165 306 174\n",
      "340\n",
      "215 200 297 221\n",
      "341\n",
      "9 82 348 218\n",
      "342\n",
      "285 167 436 211\n",
      "343\n",
      "96 307 140 432\n",
      "344\n",
      "12 226 75 302\n",
      "345\n",
      "11 86 441 350\n",
      "346\n",
      "234 115 304 163\n",
      "347\n",
      "184 66 392 229\n",
      "348\n",
      "50 223 124 261\n",
      "349\n",
      "44 86 299 190\n",
      "350\n",
      "341 247 490 272\n",
      "351\n",
      "275 290 333 430\n",
      "352\n",
      "425 4 484 304\n",
      "353\n",
      "349 35 456 279\n",
      "354\n",
      "24 63 59 188\n",
      "355\n",
      "0 115 106 275\n",
      "356\n",
      "345 174 360 184\n",
      "357\n",
      "12 81 379 195\n",
      "358\n",
      "78 179 108 237\n",
      "359\n",
      "102 382 224 390\n",
      "360\n",
      "5 12 116 164\n",
      "361\n",
      "101 308 220 344\n",
      "362\n",
      "187 247 359 412\n",
      "363\n",
      "75 131 168 249\n",
      "364\n",
      "145 233 313 334\n",
      "365\n",
      "63 81 407 83\n",
      "366\n",
      "154 112 180 250\n",
      "367\n",
      "21 180 345 238\n",
      "368\n",
      "12 131 490 307\n",
      "369\n",
      "137 182 190 250\n",
      "369\n",
      "160 493 366 497\n",
      "370\n",
      "201 133 274 191\n",
      "371\n",
      "67 20 78 176\n",
      "372\n",
      "192 88 246 305\n",
      "373\n",
      "53 249 278 291\n",
      "374\n",
      "213 21 244 334\n",
      "375\n",
      "56 153 176 354\n",
      "376\n",
      "115 43 490 143\n",
      "377\n",
      "83 16 221 85\n",
      "378\n",
      "75 112 348 358\n",
      "379\n",
      "13 81 88 184\n",
      "380\n",
      "334 305 358 320\n",
      "381\n",
      "200 256 202 260\n",
      "382\n",
      "256 84 273 153\n",
      "383\n",
      "98 145 421 304\n",
      "384\n",
      "286 135 319 314\n",
      "385\n",
      "29 241 165 258\n",
      "386\n",
      "275 218 410 271\n",
      "387\n",
      "43 116 120 325\n",
      "388\n",
      "351 238 373 308\n",
      "389\n",
      "155 137 340 277\n",
      "390\n",
      "300 100 341 114\n",
      "391\n",
      "312 13 356 297\n",
      "392\n",
      "21 194 193 195\n",
      "393\n",
      "59 51 95 137\n",
      "394\n",
      "307 107 470 212\n",
      "395\n",
      "244 351 342 412\n",
      "396\n",
      "259 285 423 353\n",
      "397\n",
      "345 92 497 239\n",
      "398\n",
      "310 177 354 204\n",
      "399\n",
      "193 161 236 222\n",
      "400\n",
      "340 90 377 184\n",
      "401\n",
      "120 84 446 191\n",
      "402\n",
      "299 229 391 247\n",
      "403\n",
      "118 180 123 190\n",
      "404\n",
      "137 41 300 124\n",
      "405\n",
      "60 142 438 335\n",
      "406\n",
      "200 182 310 205\n",
      "407\n",
      "81 370 351 418\n",
      "407\n",
      "111 95 179 185\n",
      "408\n",
      "280 248 460 279\n",
      "409\n",
      "359 174 483 353\n",
      "410\n",
      "248 304 252 433\n",
      "411\n",
      "237 304 443 338\n",
      "412\n",
      "4 202 304 393\n",
      "413\n",
      "245 159 436 189\n",
      "414\n",
      "118 205 465 299\n",
      "415\n",
      "91 190 271 490\n",
      "416\n",
      "144 137 345 244\n",
      "417\n",
      "105 69 157 176\n",
      "418\n",
      "69 83 197 261\n",
      "419\n",
      "197 136 413 258\n",
      "420\n",
      "295 120 387 293\n",
      "421\n",
      "101 51 207 330\n",
      "422\n",
      "133 213 469 240\n",
      "423\n",
      "124 269 293 280\n",
      "424\n",
      "132 59 157 109\n",
      "425\n",
      "305 214 471 326\n",
      "426\n",
      "381 148 383 241\n",
      "427\n",
      "43 172 399 252\n",
      "428\n",
      "129 10 189 149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "17 20 289 323\n",
      "430\n",
      "27 16 201 315\n",
      "431\n",
      "8 265 305 283\n",
      "432\n",
      "119 205 482 306\n",
      "433\n",
      "109 255 202 310\n",
      "434\n",
      "137 26 401 215\n",
      "435\n",
      "44 219 202 308\n",
      "436\n",
      "179 10 271 69\n",
      "437\n",
      "182 273 428 354\n",
      "438\n",
      "222 79 483 372\n",
      "439\n",
      "327 11 422 57\n",
      "440\n",
      "76 245 80 286\n",
      "441\n",
      "312 78 462 316\n",
      "442\n",
      "129 127 284 172\n",
      "443\n",
      "91 108 271 144\n",
      "444\n",
      "16 108 240 260\n",
      "445\n",
      "175 315 423 319\n",
      "446\n",
      "48 161 316 295\n",
      "447\n",
      "187 62 425 64\n",
      "448\n",
      "15 14 367 33\n",
      "449\n",
      "29 256 73 270\n",
      "450\n",
      "348 13 364 175\n",
      "451\n",
      "134 15 289 342\n",
      "452\n",
      "265 210 474 291\n",
      "453\n",
      "76 45 348 324\n",
      "454\n",
      "25 265 486 360\n",
      "455\n",
      "259 68 273 113\n",
      "456\n",
      "87 126 95 149\n",
      "457\n",
      "197 141 423 170\n",
      "458\n",
      "234 265 248 452\n",
      "459\n",
      "318 48 494 195\n",
      "460\n",
      "86 29 218 335\n",
      "461\n",
      "38 161 339 351\n",
      "462\n",
      "297 130 352 144\n",
      "463\n",
      "21 121 356 244\n",
      "464\n",
      "76 76 480 107\n",
      "465\n",
      "371 92 487 200\n",
      "466\n",
      "155 121 207 225\n",
      "467\n",
      "51 185 96 195\n",
      "468\n",
      "217 22 304 287\n",
      "469\n",
      "101 332 442 345\n",
      "470\n",
      "10 104 262 280\n",
      "471\n",
      "278 215 295 327\n",
      "472\n",
      "340 74 457 302\n",
      "473\n",
      "324 210 422 338\n",
      "474\n",
      "145 156 327 349\n",
      "475\n",
      "218 21 243 151\n",
      "476\n",
      "178 178 346 256\n",
      "477\n",
      "220 82 271 303\n",
      "478\n",
      "102 11 402 283\n",
      "479\n",
      "78 77 464 105\n",
      "480\n",
      "53 14 221 65\n",
      "481\n",
      "139 212 475 286\n",
      "482\n",
      "200 99 484 202\n",
      "483\n",
      "177 78 242 490\n",
      "484\n",
      "205 118 309 280\n",
      "485\n",
      "143 33 449 251\n",
      "486\n",
      "74 51 199 136\n",
      "487\n",
      "123 134 232 261\n",
      "488\n",
      "269 173 419 199\n",
      "489\n",
      "202 189 316 225\n",
      "490\n",
      "66 65 491 110\n",
      "491\n",
      "404 36 462 260\n",
      "492\n",
      "74 145 285 348\n",
      "493\n",
      "350 59 395 176\n",
      "494\n",
      "22 254 310 454\n",
      "495\n",
      "229 117 311 163\n",
      "496\n",
      "196 31 320 85\n",
      "497\n",
      "15 92 271 224\n",
      "498\n",
      "352 3 388 321\n",
      "499\n",
      "195 210 317 438\n",
      "500\n",
      "184 66 295 328\n",
      "501\n",
      "66 33 457 117\n",
      "502\n",
      "64 23 90 45\n",
      "503\n",
      "211 277 261 397\n",
      "504\n",
      "104 139 486 343\n",
      "505\n",
      "257 55 368 262\n",
      "506\n",
      "24 219 467 335\n",
      "507\n",
      "346 275 371 290\n",
      "508\n",
      "216 98 488 327\n",
      "509\n",
      "62 25 249 406\n",
      "510\n",
      "227 140 405 153\n",
      "511\n",
      "97 100 194 496\n",
      "512\n",
      "187 467 257 499\n",
      "513\n",
      "30 285 185 350\n",
      "514\n",
      "116 127 167 264\n",
      "515\n",
      "80 140 157 309\n",
      "516\n",
      "168 150 212 190\n",
      "517\n",
      "207 228 230 317\n",
      "518\n",
      "8 176 153 239\n",
      "519\n",
      "30 173 191 349\n",
      "520\n",
      "89 10 431 214\n",
      "521\n",
      "104 138 290 140\n",
      "522\n",
      "136 254 492 344\n",
      "523\n",
      "13 106 312 364\n",
      "524\n",
      "92 148 344 369\n",
      "525\n",
      "25 99 35 190\n",
      "526\n",
      "246 50 312 326\n",
      "527\n",
      "74 309 183 488\n",
      "528\n",
      "108 142 449 394\n",
      "529\n",
      "9 102 408 278\n",
      "530\n",
      "313 377 350 442\n",
      "530\n",
      "171 272 272 334\n",
      "531\n",
      "18 82 27 150\n",
      "532\n",
      "4 78 78 263\n",
      "533\n",
      "138 307 333 494\n",
      "534\n",
      "159 90 496 270\n",
      "535\n",
      "52 98 323 190\n",
      "536\n",
      "64 46 232 144\n",
      "537\n",
      "123 111 369 133\n",
      "538\n",
      "175 7 180 143\n",
      "539\n",
      "411 11 469 219\n",
      "540\n",
      "18 87 212 344\n",
      "541\n",
      "127 92 374 142\n",
      "542\n",
      "124 77 493 97\n",
      "543\n",
      "132 48 206 306\n",
      "544\n",
      "344 61 435 148\n",
      "545\n",
      "127 38 169 185\n",
      "546\n",
      "12 0 450 121\n",
      "547\n",
      "289 226 296 303\n",
      "548\n",
      "104 54 169 248\n",
      "549\n",
      "16 143 443 203\n",
      "550\n",
      "346 169 393 292\n",
      "551\n",
      "249 267 456 306\n",
      "552\n",
      "94 6 105 218\n",
      "553\n",
      "49 291 119 428\n",
      "554\n",
      "116 20 143 334\n",
      "555\n",
      "149 263 170 406\n",
      "556\n",
      "155 101 481 185\n",
      "557\n",
      "53 165 327 284\n",
      "558\n",
      "178 92 397 143\n",
      "559\n",
      "262 345 356 356\n",
      "560\n",
      "32 38 338 116\n",
      "561\n",
      "248 28 286 478\n",
      "562\n",
      "59 151 199 323\n",
      "563\n",
      "241 60 370 84\n",
      "564\n",
      "18 189 304 297\n",
      "565\n",
      "156 71 479 372\n",
      "566\n",
      "88 370 115 448\n",
      "567\n",
      "369 140 466 227\n",
      "568\n",
      "135 55 204 196\n",
      "569\n",
      "259 11 452 259\n",
      "570\n",
      "124 141 265 190\n",
      "571\n",
      "414 1 486 91\n",
      "572\n",
      "348 143 454 311\n",
      "573\n",
      "35 232 229 304\n",
      "574\n",
      "448 34 457 210\n",
      "575\n",
      "50 68 456 172\n",
      "576\n",
      "257 27 399 177\n",
      "577\n",
      "105 252 153 268\n",
      "578\n",
      "68 199 126 318\n",
      "578\n",
      "363 190 474 282\n",
      "579\n",
      "50 54 441 293\n",
      "580\n",
      "441 21 499 313\n",
      "581\n",
      "204 340 277 424\n",
      "582\n",
      "86 54 274 149\n",
      "583\n",
      "19 81 284 330\n",
      "584\n",
      "72 68 448 277\n",
      "585\n",
      "87 63 250 238\n",
      "586\n",
      "168 144 466 214\n",
      "587\n",
      "457 72 462 183\n",
      "588\n",
      "129 75 231 176\n",
      "589\n",
      "96 67 296 452\n",
      "590\n",
      "65 185 99 344\n",
      "591\n",
      "28 16 68 187\n",
      "592\n",
      "29 146 212 276\n",
      "593\n",
      "249 73 338 305\n",
      "594\n",
      "20 138 196 224\n",
      "595\n",
      "167 145 485 348\n",
      "596\n",
      "201 72 348 300\n",
      "597\n",
      "73 416 339 423\n",
      "598\n",
      "336 221 396 343\n",
      "599\n",
      "14 86 276 260\n",
      "600\n",
      "66 66 365 75\n",
      "601\n",
      "294 9 313 71\n",
      "602\n",
      "304 234 347 293\n",
      "603\n",
      "201 432 369 476\n",
      "604\n",
      "36 121 147 250\n",
      "605\n",
      "88 198 472 361\n",
      "606\n",
      "239 322 267 489\n",
      "606\n",
      "459 120 488 253\n",
      "607\n",
      "289 69 338 288\n",
      "608\n",
      "231 190 251 281\n",
      "609\n",
      "45 131 182 144\n",
      "610\n",
      "59 142 262 175\n",
      "611\n",
      "261 115 302 257\n",
      "612\n",
      "133 107 351 251\n",
      "613\n",
      "226 66 413 113\n",
      "614\n",
      "277 163 343 269\n",
      "615\n",
      "15 156 224 302\n",
      "616\n",
      "143 136 293 367\n",
      "617\n",
      "90 359 300 373\n",
      "618\n",
      "136 31 403 104\n",
      "619\n",
      "3 178 460 321\n",
      "620\n",
      "48 77 209 176\n",
      "621\n",
      "164 324 398 395\n",
      "622\n",
      "203 28 280 340\n",
      "623\n",
      "47 182 58 273\n",
      "624\n",
      "58 51 487 202\n",
      "625\n",
      "211 233 388 329\n",
      "626\n",
      "48 257 133 299\n",
      "627\n",
      "105 95 125 258\n",
      "628\n",
      "238 134 287 363\n",
      "629\n",
      "154 205 438 226\n",
      "630\n",
      "17 8 178 141\n",
      "631\n",
      "364 292 389 369\n",
      "632\n",
      "297 236 335 240\n",
      "633\n",
      "109 61 134 303\n",
      "634\n",
      "396 92 467 251\n",
      "635\n",
      "111 6 323 87\n",
      "636\n",
      "76 143 457 175\n",
      "637\n",
      "14 53 481 72\n",
      "638\n",
      "334 203 346 211\n",
      "639\n",
      "179 125 230 343\n",
      "640\n",
      "380 193 442 235\n",
      "641\n",
      "66 192 400 327\n",
      "642\n",
      "63 58 231 143\n",
      "643\n",
      "22 89 23 134\n",
      "644\n",
      "72 223 123 278\n",
      "645\n",
      "363 320 398 335\n",
      "646\n",
      "127 79 181 86\n",
      "647\n",
      "110 55 147 129\n",
      "648\n",
      "154 41 208 116\n",
      "649\n",
      "167 135 240 361\n",
      "650\n",
      "263 236 365 366\n",
      "651\n",
      "186 49 310 370\n",
      "652\n",
      "126 264 415 368\n",
      "653\n",
      "40 29 384 171\n",
      "654\n",
      "97 97 298 256\n",
      "655\n",
      "35 8 98 233\n",
      "656\n",
      "18 96 489 320\n",
      "657\n",
      "358 1 421 451\n",
      "658\n",
      "251 30 499 250\n",
      "659\n",
      "63 49 337 227\n",
      "660\n",
      "312 280 487 291\n",
      "661\n",
      "277 151 343 271\n",
      "662\n",
      "62 180 202 347\n",
      "663\n",
      "249 53 451 170\n",
      "664\n",
      "83 8 148 193\n",
      "665\n",
      "188 233 493 279\n",
      "666\n",
      "24 255 122 497\n",
      "667\n",
      "118 235 449 300\n",
      "668\n",
      "114 136 303 233\n",
      "669\n",
      "38 155 247 226\n",
      "670\n",
      "216 1 241 73\n",
      "671\n",
      "149 12 369 107\n",
      "672\n",
      "192 114 488 288\n",
      "673\n",
      "168 113 447 311\n",
      "674\n",
      "85 125 88 223\n",
      "675\n",
      "36 169 297 330\n",
      "676\n",
      "215 106 421 176\n",
      "677\n",
      "161 7 359 219\n",
      "678\n",
      "56 19 126 94\n",
      "679\n",
      "93 89 322 295\n",
      "680\n",
      "175 113 314 248\n",
      "681\n",
      "328 122 425 328\n",
      "682\n",
      "2 263 464 300\n",
      "683\n",
      "136 74 223 351\n",
      "684\n",
      "161 60 244 71\n",
      "685\n",
      "295 136 337 349\n",
      "686\n",
      "144 2 190 496\n",
      "687\n",
      "12 20 448 40\n",
      "688\n",
      "59 199 226 274\n",
      "689\n",
      "81 104 292 252\n",
      "690\n",
      "84 256 398 270\n",
      "691\n",
      "12 117 199 283\n",
      "692\n",
      "281 255 477 313\n",
      "693\n",
      "0 177 227 323\n",
      "694\n",
      "72 65 376 87\n",
      "695\n",
      "224 95 376 138\n",
      "696\n",
      "335 219 380 306\n",
      "697\n",
      "111 216 195 295\n",
      "698\n",
      "121 46 222 128\n",
      "699\n",
      "195 147 273 205\n",
      "700\n",
      "232 79 334 365\n",
      "701\n",
      "351 98 374 253\n",
      "702\n",
      "438 8 454 310\n",
      "703\n",
      "243 228 289 329\n",
      "704\n",
      "90 76 194 178\n",
      "705\n",
      "60 258 146 319\n",
      "706\n",
      "183 186 321 241\n",
      "707\n",
      "158 92 200 219\n",
      "708\n",
      "85 219 138 339\n",
      "709\n",
      "190 128 229 190\n",
      "710\n",
      "156 247 459 343\n",
      "711\n",
      "67 20 98 90\n",
      "712\n",
      "36 108 343 196\n",
      "713\n",
      "335 162 482 235\n",
      "714\n",
      "69 304 102 340\n",
      "715\n",
      "242 92 246 248\n",
      "716\n",
      "80 29 412 150\n",
      "717\n",
      "29 52 315 91\n",
      "718\n",
      "162 206 241 311\n",
      "719\n",
      "325 164 392 281\n",
      "720\n",
      "217 19 474 252\n",
      "721\n",
      "208 236 355 287\n",
      "722\n",
      "50 30 100 125\n",
      "723\n",
      "69 98 438 323\n",
      "724\n",
      "221 16 280 40\n",
      "725\n",
      "170 104 206 392\n",
      "726\n",
      "178 289 318 353\n",
      "727\n",
      "288 16 299 191\n",
      "728\n",
      "466 113 473 271\n",
      "729\n",
      "302 39 306 267\n",
      "730\n",
      "97 216 140 226\n",
      "731\n",
      "183 328 331 336\n",
      "732\n",
      "70 5 260 19\n",
      "733\n",
      "438 224 450 267\n",
      "734\n",
      "467 259 484 316\n",
      "735\n",
      "28 11 64 108\n",
      "736\n",
      "163 113 487 297\n",
      "737\n",
      "84 117 317 156\n",
      "738\n",
      "94 229 166 285\n",
      "739\n",
      "204 26 394 109\n",
      "740\n",
      "53 226 210 306\n",
      "741\n",
      "316 32 417 172\n",
      "742\n",
      "298 64 310 124\n",
      "743\n",
      "78 156 296 333\n",
      "744\n",
      "253 206 333 267\n",
      "745\n",
      "356 119 498 315\n",
      "746\n",
      "147 302 327 318\n",
      "747\n",
      "124 39 325 189\n",
      "748\n",
      "236 18 373 132\n",
      "749\n",
      "230 39 373 48\n",
      "750\n",
      "278 18 282 204\n",
      "751\n",
      "306 154 373 320\n",
      "752\n",
      "70 161 264 183\n",
      "753\n",
      "154 78 198 277\n",
      "754\n",
      "182 40 252 326\n",
      "755\n",
      "107 61 140 87\n",
      "756\n",
      "272 198 306 263\n",
      "757\n",
      "185 86 445 312\n",
      "758\n",
      "235 215 365 273\n",
      "759\n",
      "95 59 204 354\n",
      "760\n",
      "43 88 293 258\n"
     ]
    }
   ],
   "source": [
    "def build_background_class():\n",
    "    dir_names = os.listdir('data/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations')\n",
    "    average = int(sum(counts[1:])/len(counts[1:]))\n",
    "    counts[0] = 0\n",
    "    while(counts[0]!=average):        \n",
    "        print(counts[0])\n",
    "        select = 1\n",
    "        img_name = random.choice(dir_names)\n",
    "        tree = ET.parse('data/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations/' + img_name)\n",
    "        root = tree.getroot()\n",
    "        img = Image.open('data/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/' + img_name[0:-4] + '.jpg')\n",
    "        imsize = img.size;\n",
    "        x1 = random.randrange(imsize[0])\n",
    "        x2 = random.randrange(imsize[0])\n",
    "        y1 = random.randrange(imsize[1])\n",
    "        y2 = random.randrange(imsize[1])\n",
    "        if(x1>x2):\n",
    "            temp = x1\n",
    "            x1=x2\n",
    "            x2=temp\n",
    "        if(y1>y2):\n",
    "            temp = y1\n",
    "            y1=y2\n",
    "            y2=temp\n",
    "        print(x1,y1,x2,y2)\n",
    "        if(x1==x2 or y1==y2):\n",
    "            continue\n",
    "        for object1 in root.iter('object'):\n",
    "            for name1 in object1.iter('name'):\n",
    "                dirname = name1.text\n",
    "            for bndbox in object1.iter('bndbox'):\n",
    "                intersection = 0\n",
    "                for xmin in object1.iter('xmin'):\n",
    "                    xa = int(float(xmin.text))\n",
    "                for xmax in object1.iter('xmax'):\n",
    "                    xb = int(float(xmax.text))\n",
    "                for ymin in object1.iter('ymin'):\n",
    "                    ya = int(float(ymin.text))\n",
    "                for ymax in object1.iter('ymax'):\n",
    "                    yb = int(float(ymax.text))\n",
    "                ra = Rectangle(x1, x2, y1, y2)\n",
    "                rb = Rectangle(xa, xb, ya, yb)\n",
    "                if(area(ra,rb)!=None):\n",
    "                    intersection = area(ra,rb)\n",
    "                union = ((x2-x1)*(y2-y1))+((xb-xa)*(yb-ya))-intersection\n",
    "                if(float(intersection)/union>0.5):\n",
    "                    select = 0\n",
    "\n",
    "        if(select==1):\n",
    "            img = img.crop((x1,y1,x2,y2)).resize((resnet_input,resnet_input))\n",
    "            img.save('data/train/__background__/' + str(counts[0]) + \".jpg\");\n",
    "            counts[0] += 1\n",
    "    \n",
    "build_background_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class hound_dataset(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # Begin\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        if train == True:\n",
    "            dir1 = '/train/'\n",
    "        else:\n",
    "            dir1 = '/test/'\n",
    "        \n",
    "        dir_names = os.listdir(root_dir + dir1)\n",
    "        img_names=[]\n",
    "        labels = []\n",
    "        count = 0\n",
    "        for c in dir_names:\n",
    "            names = os.listdir(root_dir + dir1 + c)\n",
    "            N = len(names)\n",
    "            for n in range(N):\n",
    "                img_names.append(str(root_dir + dir1 + c + '/' + names[n]))\n",
    "                labels += [count]\n",
    "            count+=1\n",
    "               \n",
    "        \n",
    "        self.img_names = img_names\n",
    "        self.labels = labels  \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Begin\n",
    "        \n",
    "        return len(self.img_names)        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Begin\n",
    "        \n",
    "        img_pil = Image.open(self.img_names[idx]).convert('RGB')\n",
    "        return self.transform(img_pil), self.labels[idx]       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "<br/>You can ask Arya to train the network on the created dataset. This will yield a classification network on the 21 classes of the VOC dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((resnet_input,resnet_input)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.RandomHorizontalFlip()])\n",
    "train_dataset = hound_dataset(root_dir='./data', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "#test_dataset = hound_dataset(root_dir='./data', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "Litlefinger has brought you a pre-trained network. Fine-tune the network in the following section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet (\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU (inplace)\n",
       "  (maxpool): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "  (layer1): Sequential (\n",
       "    (0): BasicBlock (\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): BasicBlock (\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): BasicBlock (\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock (\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential (\n",
       "    (0): BasicBlock (\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock (\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential (\n",
       "    (0): BasicBlock (\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock (\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d (size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (fc): Linear (512 -> 21)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 21)\n",
    "resnet18.cuda()\n",
    "\n",
    "# Add code for using CUDA here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Update if any errors occur\n",
    "optimizer = optim.SGD(resnet18.fc.parameters(), learning_rate, hyp_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arya_train():\n",
    "    # Begin\n",
    "    for epoch in range(num_epochs): \n",
    "        resnet18.train()        \n",
    "        for i, (input1,target) in enumerate(train_loader):\n",
    "            \n",
    "            input_var = torch.autograd.Variable(input1).cuda()            \n",
    "            target = target.cuda(async = True)\n",
    "            target_var = torch.autograd.Variable(target)\n",
    "            \n",
    "            output = resnet18(input_var)            \n",
    "            loss = criterion(output, target_var)           \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "            \n",
    "            print(str(epoch)+ '---'+str(i) + '--------' +  str(loss) + '-------' +str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time arya_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Accuracy Calculation\n",
    "Jorah then asks a question, how is this a detection task?<br/>\n",
    "As everybody wonders, Theon Greyjoy suggests a slding window method to test the above trained trained network on the detection task:<br/>\n",
    "\"We take some windows of varying size and aspect ratios\", he mumbled, \"and slide it through the test image (considering some stride of pixels) from left to right, and top to bottom, detect the class scores for each of the window, and keep only those which are above a certain threshold value!\". \"He is right\", says Samwell, \"I read a similar approach in the paper -Faster RCNN by Ross Girshick in the library, where he uses three diferent scales/sizes and three different aspect ratios, making a total of nine windows per pixel to slide\". You need to write the code and use it in testing code to find the predicted boxes and their classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-96. -48. -96. -64. -32. -64. -32. -16. -32.]\n"
     ]
    }
   ],
   "source": [
    "def theon_sliding_window():\n",
    "    # Begin\n",
    "    boxes=[]\n",
    "    imres = [[192,192],[192,96],[96,192],[128,128],[128,64],[64,128],[64,64],[64,32],[32,64]]\n",
    "    for i in range(resnet_input):\n",
    "        for j in range(resnet_input):\n",
    "            for window in imres:\n",
    "                boxes.append([i-window[0]/2, j-window[1]/2, i+window[0]/2, j+window[1]/2])\n",
    "    return np.asarray(np.array(boxes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wait\", says <b>Jon Snow</b>, \"The predicted boxes may be too many and we can't deal with all of them. So, I myself will go and apply non_maximum_supression to reduce the number of boxes\". You are free to choose the threshold value for non maximum supression, but choose wisely [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aegon_targaryen_non_maximum_supression(boxes,threshold = 0.3):\n",
    "            \n",
    "        pick = []\n",
    "\n",
    "        x1 = boxes[:,0]\n",
    "        y1 = boxes[:,1]\n",
    "        x2 = boxes[:,2]\n",
    "        y2 = boxes[:,3]\n",
    "\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        idxs = np.argsort(y2)\n",
    "        \n",
    "        while len(idxs) > 0:\n",
    "            \n",
    "            last = len(idxs) - 1\n",
    "            i = idxs[last]\n",
    "            pick.append(i)\n",
    "            suppress = [last]\n",
    "            \n",
    "            for pos in xrange(0, last):\n",
    "                \n",
    "                j = idxs[pos]\n",
    "               \n",
    "                xx1 = max(x1[i], x1[j])\n",
    "                yy1 = max(y1[i], y1[j])\n",
    "                xx2 = min(x2[i], x2[j])\n",
    "                yy2 = min(y2[i], y2[j])\n",
    "               \n",
    "                w = max(0, xx2 - xx1 + 1)\n",
    "                h = max(0, yy2 - yy1 + 1)\n",
    "\n",
    "                overlap = float(w * h) / area[j]\n",
    "\n",
    "                if overlap > threshold:\n",
    "                    suppress.append(pos)\n",
    "\n",
    "            idxs = np.delete(idxs, suppress)\n",
    "\n",
    "        return boxes[pick]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Daenerys, the queen, then orders her army to test out the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daenerys_test(resnet18):\n",
    "    # Write loops for testing the model on the test set\n",
    "    # Also print out the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time daenerys_test(resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Showdown\n",
    "After covering all the steps and passing the accuracy value to the talking crystal, they all pass through to the land of the living, with a wounded Jon Snow armed with the Dragon-axe. After a fierce battle, Jon Snow manages to go face to face with the Night king. Surrounded by battling men and falling bodies, they engage in a ferocious battle, a battle of spear and axe. After a raging fight, Jon manages to sink the axe into the Night king's heart, but not before he gets wounded by the spear. As dead men fall to bones, Daenerys and others rush to his aid, but it is too late. Everyone is in tears as they look towards the man of honour, Jon Snow, lying in Daenerys's arms when he says his last words: \"The night has ended. Winter is finally over!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
