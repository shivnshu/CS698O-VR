{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Networks\n",
    "In this notebook you have to create a custom network whose architecture has been given, and use the dataset you created earlier to train and test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "Change root dir and CIFAR dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "#\n",
    "# Several of the imports you will need have been added but you will need to provide the\n",
    "# rest yourself; you should be able to figure out most of the imports as you go through\n",
    "# the notebook since without proper imports your code will fail to run\n",
    "#\n",
    "# All import statements go in this block\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All hyper parameters go in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Dataset and Loader\n",
    "This is the same as part 1. Simply use the same code to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # root_dir  - the root directory of the dataset\n",
    "        # train     - a boolean parameter representing whether to return the training set or the test set\n",
    "        # transform - the transforms to be applied on the images before returning them\n",
    "        #\n",
    "        # In this function store the parameters in instance variables and make a mapping\n",
    "        # from images to labels and keep it as an instance variable. Make sure to check which\n",
    "        # dataset is required; train or test; and create the mapping accordingly.        \n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        if train == True:\n",
    "            dir1 = '/train/'\n",
    "        else:\n",
    "            dir1 = '/test/'\n",
    "        \n",
    "        dir_names = os.listdir(root_dir + dir1)\n",
    "        img_names=[]\n",
    "        labels = []\n",
    "        count = 0\n",
    "        for c in dir_names[0:10]:\n",
    "            names = os.listdir(root_dir + dir1 + c)\n",
    "            N = len(names)\n",
    "            for n in range(N):\n",
    "                img_names.append(str(root_dir + dir1 + c + '/' + names[n]))\n",
    "                labels += [count]\n",
    "            count+=1\n",
    "               \n",
    "        \n",
    "        self.img_names = img_names\n",
    "        self.labels = labels        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        \n",
    "        return len(self.img_names)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # idx - the index of the sample requested\n",
    "        # Open the image correspoding to idx, apply transforms on it and return a tuple (image, label)\n",
    "        # where label is an integer from 0-9 (since notMNIST has 10 classes)\n",
    "        #temp = mpimg.imread(self.img_names[idx])\n",
    "        \n",
    "        img_pil = Image.open(self.img_names[idx]).convert('RGB')\n",
    "        return self.transform(img_pil), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((32,32)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='./data/', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='./data/', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Network\n",
    "It's time to create a new custom network. This network is based on Resnet (indeed it is a resnet since it uses skip connections). The architecture of the network is provided in the diagram. It specifies the layer names, layer types as well as their parameters.\n",
    "<img src=\"architecture.png\" width=100>\n",
    "[Full size image](architecture.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomResnet(nn.Module): # Extend PyTorch's Module class\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(CustomResnet, self).__init__() # Must call super __init__()\n",
    "        \n",
    "        # Define the layers of the network here\n",
    "        # There should be 17 total layers as evident from the diagram\n",
    "        # The parameters and names for the layers are provided in the diagram\n",
    "        # The variable names have to be the same as the ones in the diagram\n",
    "        # Otherwise, the weights will not load\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=True)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(64)\n",
    "        self.relu =torch.nn.ReLU(True)\n",
    "        self.maxpool= torch.nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        \n",
    "        self.lyr1conv1 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=True)\n",
    "        self.lyr1bn1 = torch.nn.BatchNorm1d(64)\n",
    "        self.lyr1relu1 =torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.lyr1conv2 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=True)\n",
    "        self.lyr1bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.lyr1relu2 =torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.lyr2conv1 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=True)\n",
    "        self.lyr2bn1 = torch.nn.BatchNorm1d(64)\n",
    "        self.lyr2relu1 =torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.lyr2conv2 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=True)\n",
    "        self.lyr2bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.lyr2relu2 =torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(4096, num_classes)\n",
    "        \n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here you have to define the forward pass\n",
    "        # Make sure you take care of the skip connections\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x1 = self.maxpool(x)\n",
    "\n",
    "        x = self.lyr1conv1(x1)\n",
    "        x = self.lyr1bn1(x)\n",
    "        x = self.lyr1relu1(x)\n",
    "        \n",
    "        x = self.lyr1conv2(x)\n",
    "        x = self.lyr1bn2(x)\n",
    "        x1 = self.lyr1relu2(x+x1)\n",
    "        \n",
    "        x = self.lyr2conv1(x1)\n",
    "        x = self.lyr2bn1(x)\n",
    "        x = self.lyr2relu1(x)\n",
    "        \n",
    "        x = self.lyr2conv2(x)\n",
    "        x = self.lyr2bn2(x)\n",
    "        x = self.lyr2relu2(x+x1)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune on pre-trained CIFAR-100 weights\n",
    "We shall now finetune our model using pretrained CIFAR-100 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CustomResnet(num_classes = 100) # 100 classes since CIFAR-100 has 100 classes\n",
    "\n",
    "# Load CIFAR-100 weights. (Download them from assignment page)\n",
    "# If network was properly implemented, weights should load without any problems\n",
    "model.load_state_dict(torch.load('./CIFAR-100_weights')) # Supply the path to the weight file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional\n",
    "As a sanity check you may load the CIFAR-100 test dataset and test the above model. You should get an accuracy of ~41%. This part is optional and is meant for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Block for optionally running the model on CIFAR-100 test set\n",
    "# composed_transform = transforms.Compose([transforms.Scale((32,32)),transforms.ToTensor()])\n",
    "# train_dataset = CDATA(root_dir='../a1/', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "# test_dataset = CDATA(root_dir='../a1/', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finetune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([54, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([54, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([54, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([54, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([54, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4lOd57/HvrYVVYpUEAgmzSWAwu4zxxuYlNrHrLIY4\naetz3NPSpHZqx27dNj1N2p6mPXVS13Hs2uUkbuPUSRAhdr3g1gticWJjDZjFZhWbRyCQkIxAArQ+\n548ZKYoyoJGYmXeW3+e6dDGaeZj35gF+vDzvM/drzjlERCS5pHldgIiIRJ7CXUQkCSncRUSSkMJd\nRCQJKdxFRJKQwl1EJAkp3EVEkpDCXUQkCSncRUSSUIZXB87JyXHjx4/36vAiIglp69atp5xzuT2N\n8yzcx48fj8/n8+rwIiIJycyOhjNOyzIiIklI4S4ikoQU7iIiSUjhLiKShBTuIiJJSOEuIpKEFO4i\nIklI4S4iEkNPvLWf9w7VRv04CncRkRj5uPYcT7x1gPLDdVE/lsJdRCRGfrbVjxncXVIQ9WMp3EVE\nYqCt3bFmayULi3LJHzow6sdTuIuIxMA7Faeoqr/AF64ujMnxFO4iIjFQWu5n+KBMbroyLybHU7iL\niERZXWMzb+w+wWfnFNA/Iz0mx+wx3M1sgJm9b2Y7zOwjM/ubEGPMzJ40swoz22lmc6NTrohI4nnp\ng2O0tDlWXB39C6kdwunn3gQsdc41mFkm8I6Zve6ce6/LmNuBouDXNcAzwR9FRFKac45Sn59ZBUOZ\nOnpIzI7b45m7C2gIfpsZ/HLdht0FPB8c+x4wzMzyI1uqiEji2XWsnr0nzrK8JDYXUjuEteZuZulm\nth2oBt50zm3pNmQs4O/yfWXwORGRlLa63E//jDR+a/aYmB43rHB3zrU552YDBcB8M7uqLwczs5Vm\n5jMzX01NTV/eQkQkYZxvbuPl7cdZNiOfIQMyY3rsXu2Wcc6dBsqA27q9dAzo+n+OguBz3X/+Kudc\niXOuJDe3x/u7iogktP/6qIqzTa2siPGSDIS3WybXzIYFHw8EbgH2dhv2MnBvcNfMAqDeOVcV8WpF\nRBJIaXkl40YM4poJI2J+7HB2y+QDPzSzdAL/GJQ65141sy8DOOeeBdYBy4AK4BxwX5TqFRFJCEdr\nG3n3UC1/cmsxaWkW8+P3GO7OuZ3AnBDPP9vlsQPuj2xpIiKJ62dbK0kz+Py82O1t70qfUBURibC2\ndsfPtlaysDg2TcJCUbiLiETY5gM1gSZhHlxI7aBwFxGJsFKfnxGD+3HTlaM8q0HhLiISQXWNzby5\n+ySfnTOWfhneRazCXUQkgl7saBLm4ZIMKNxFRCLGOccan59ZhcOYMjrb01oU7iIiEbKzMtAkbEUM\n7pHaE4W7iEiErPb5GZCZxp2zYtskLBSFu4hIBJxvbuOV7cdZdlXsm4SFonAXEYmA1z8MNgmL0Q2w\ne6JwFxGJgFKfnytGetMkLBSFu4jIZTpa28h7h+pYUVKIWeybhIWicBcRuUxrfMEmYXO93yXTQeEu\nInIZOpqELSrOZfTQAV6X00nhLiJyGTYdqOHEmQt8IU4upHZQuIuIXIbScj8jB/dj6VTvmoSFonAX\nEemj2oYm3trjfZOwUOKrGhGRBNLZJCzOlmRA4S4i0ifOOUp9fmYXDqN4lLdNwkJRuIuI9MGOynr2\nn2zwvLXvxSjcRUT6YHV5R5OwfK9LCUnhLiLSS+eb23hlx3GWzcgnOw6ahIWicBcR6aV1u6poaGr1\n9AbYPVG4i4j0UqnPz/iRg5gfJ03CQukx3M2s0MzKzGy3mX1kZg+GGLPYzOrNbHvw6xvRKVdExFtH\nTjWy5XAdy+OoSVgoGWGMaQUecc5tM7NsYKuZvemc291t3Gbn3B2RL1FEJH6s2eonzeDuefHTJCyU\nHs/cnXNVzrltwcdngT3A2GgXJiISb1rb2vnZ1koWT8lj1JD4aRIWSq/W3M1sPDAH2BLi5evMbKeZ\nvW5m0yNQm4hIXNl84BQnzzTF7d72rsJZlgHAzLKAtcBDzrkz3V7eBoxzzjWY2TLgJaAoxHusBFYC\njBs3rs9Fi4h4YXVnk7A8r0vpUVhn7maWSSDYX3DO/bz76865M865huDjdUCmmeWEGLfKOVfinCvJ\nzc29zNJFRGKno0nY5+bGX5OwUMLZLWPAD4A9zrnHLzJmdHAcZjY/+L61kSxURMRLL35wjNZ2lxBL\nMhDessz1wO8Cu8xse/C5rwPjAJxzzwJ3A18xs1bgPHCPc85FoV4RkZhzzrG63M+cccMoisMmYaH0\nGO7OuXeAS27mdM49BTwVqaJEROLJdv9pDlQ38A+fm+F1KWGL/4UjERGPlfr8DMxM546Z8dkkLBSF\nu4jIJZxrbuWVHVVx3SQsFIW7iMglrNt1ItAkLA7vtnQpCncRkUso9fmZkDOYq8cP97qUXlG4i4hc\nxOFTjbx/uI7lJQVx3SQsFIW7iMhFrPH5SU8z7p4b303CQlG4i4iE0NkkrDiXvDhvEhaKwl1EJIRN\nB2qoPtvEigS7kNpB4S4iEsLqcj85WYnRJCwUhbuISDenGpp4e081n5tbQGZ6YsZkYlYtIhJFL27r\naBKWeBdSOyjcRUS6cM6x2udn7rhhTM5LjCZhoSjcRUS6+MB/morqhoRp7XsxCncRkS5Ky4NNwmaN\n8bqUy6JwFxEJCjQJO86nZ+aT1T/su5DGJYW7iEjQazuraGxuS7gmYaEo3EVEgtb4KpmYM5iSKxKr\nSVgoCncREeBQTQPvH6ljeUlhwjUJC0XhLiICrNlaSXqa8fm5Y70uJSIU7iKS8lrb2lm7tZIlUxKz\nSVgoCncRSXkb9webhCX43vauFO4ikvICTcL6syRBm4SFonAXkZRWc7aJ9Xur+fzcsQnbJCyU5PmV\niIj0wYsfVNLa7lieREsyEEa4m1mhmZWZ2W4z+8jMHgwxxszsSTOrMLOdZjY3OuWKiESOc47V5X7m\nXTGcyXlZXpcTUeGcubcCjzjnpgELgPvNbFq3MbcDRcGvlcAzEa1SRCQKtn18moM1jQnd2vdiegx3\n51yVc25b8PFZYA/QfSPoXcDzLuA9YJiZ5Ue8WhGRCCot9zOoXzqfnpnYTcJC6dWau5mNB+YAW7q9\nNBbwd/m+kt/8BwAzW2lmPjPz1dTU9K5SEZEIamxq5dWdx7kjCZqEhRJ2uJtZFrAWeMg5d6YvB3PO\nrXLOlTjnSnJzc/vyFiIiEfHarkCTsGTa295VWOFuZpkEgv0F59zPQww5BnSdoYLgcyIicWmNz8/E\n3MHMS4ImYaGEs1vGgB8Ae5xzj19k2MvAvcFdMwuAeudcVQTrFBGJmIM1DZQf+YQVSdIkLJRwFpqu\nB34X2GVm24PPfR0YB+CcexZYBywDKoBzwH2RL1VEJDLW+AJNwj6XJE3CQukx3J1z7wCX/KfNOeeA\n+yNVlIhItLS2tbN2WyVLpuSRl50cTcJC0SdURSSlbNhXQ83ZpqS429KlKNxFJKWs9gWahC2ektw7\n9hTuIpIyqs9eCDQJm5dcTcJCSe5fnYhIFy9uO0Zbu2P5vORekgGFu4ikCOccq31+SpKwSVgoCncR\nSQnbPv6EQzWNSfuJ1O4U7iKSElaX+xncL51Pz0yNnoYKdxFJeoEmYVXcMXMMg5OwSVgoCncRSXqv\n7aziXHMbK65Ovr7tF6NwF5GkV+rzMyl3MHPHJWeTsFAU7iKS1CqqG/AdTe4mYaEo3EUkqa3Z6g82\nCUudJRlQuItIEmtpa2ft1mMsnZpHbnZ/r8uJKYW7iCStsr3VnGpo4gspsre9K4W7iCStUl8ludnJ\n3yQsFIW7iCSl6jMXKNtXzefnFpCR5E3CQkm9X7GIpISffxBsElaSWhdSOyjcRSTpOOcoLfdz9fjh\nTMpN/iZhoSjcRSTpbD36CYdONbI8BS+kdlC4i0jS6WwSNiM1moSFonAXkaTS0NTKa7uquHNW6jQJ\nC0XhLiJJ5bWdxznX3JbSSzKgcBeRJFPqq2RyXhZzxw3zuhRP9RjuZvacmVWb2YcXeX2xmdWb2fbg\n1zciX6aISM8qqs+y9egnrCgpSKkmYaGEsyD178BTwPOXGLPZOXdHRCoSEemjNb5KMtKMz85Jzb3t\nXfV45u6c2wTUxaAWEZE+a2lrZ+22ypRsEhZKpNbcrzOznWb2uplNj9B7ioiEbf3eak41NPOFq1P7\nQmqHSOwT2gaMc841mNky4CWgKNRAM1sJrAQYN25cBA4tIhKwxucnL7s/i4pTr0lYKJd95u6cO+Oc\nawg+XgdkmlnORcaucs6VOOdKcnP1GyAikRFoElbD5+elZpOwUC57FsxstAUvS5vZ/OB71l7u+4qI\nhGvttmCTsHm6kNqhx2UZM/sJsBjIMbNK4JtAJoBz7lngbuArZtYKnAfucc65qFUsItKFc441Pj/z\nx49gYoo2CQulx3B3zn2xh9efIrBVUkQk5nzBJmF/tGSy16XEFS1OiUhCW13uJ6t/BstmjPa6lLii\ncBeRhNXQ1MprO6u4c1Y+g/qlbpOwUBTuIpKwXt1xnPMtahIWisJdRBJWqc9PUV4WcwpTu0lYKAp3\nEUlIFdVn2fbxaVaUFKZ8k7BQFO4ikpBWl/sDTcLmjvW6lLikcBeRhNPS1s7Ptx3jpivzyMlSk7BQ\nFO4iknDe3lNNbaOahF2Kwl1EEk5Hk7CFRepRdTEKdxFJKCfPXKBsXzV3q0nYJWlmRCShrN1WSbtD\ne9t7oHAXkYQRaBJWyfwJI5iQM9jrcuKawl1EEkb5kU84fKqRL+isvUcKdxFJGB1Nwm5Xk7AeKdxF\nJCGcvdDCul1V3DlrjJqEhUHhLiIJ4dWdVZxvaWNFie62FA6Fu4gkhFKfn+JRWcxWk7CwKNxFJO4d\nOHmWD9QkrFcU7iIS9zqbhM1Rk7BwKdxFJK41t7bz4gfHuPnKUYxUk7CwKdxFJK6t33tSTcL6QOEu\nInGt1FfJqCH9ubEox+tSEorCXUTi1on6C2xQk7A+0WyJSNzqbBI2T0syvdVjuJvZc2ZWbWYfXuR1\nM7MnzazCzHaa2dzIlykiqSbQJMzPNRNGMF5NwnotnDP3fwduu8TrtwNFwa+VwDOXX5aIpLr3D9dx\npPacLqT2UY/h7pzbBNRdYshdwPMu4D1gmJnlR6pAEUlNq31+svtncPtVipO+iMSa+1jA3+X7yuBz\nv8HMVpqZz8x8NTU1ETi0iCSjziZhs8cwsF+61+UkpJheUHXOrXLOlTjnSnJzde9DEQntlR1VXGhp\nZ4X6tvdZJML9GND1d6Ag+JyISJ+s9vmZMiqbWQVDvS4lYUUi3F8G7g3umlkA1DvnqiLwviKSgvad\nOMsO/2mWlxSoSdhl6LHjvZn9BFgM5JhZJfBNIBPAOfcssA5YBlQA54D7olWsiCS/Up+fzHQ1Cbtc\nPYa7c+6LPbzugPsjVpGIpCw1CYscfUJVROLG23tOUtfYzArtbb9sCncRiRulPj+jhwxgYZF2012u\nhAt35xynGpq8LkNEIuxE/QU27q/h7nkFpKfpQurlSrhwf3tPNdf/3/V867Xd1CrkRZJGZ5Mw3QA7\nIhIu3ItHZfPpmfn84J3D3PhYGd/+772cPtfsdVkichna2x2lPj8LJo7gipFqEhYJCRfu40YO4vEV\ns3nja4tYOjWPp8sOcuM/lvHEW/s5e6HF6/JEpA/eP1LHUTUJi6iEC/cOk/OyeOpLc3n9wRu5dtJI\nnnjrADc+Vsa/bKjgXHOr1+WJSC+UlgeahN02XU3CIiVhw73DlflDWHVvCa88cANzCofx2H/tY+Fj\nZXx/8yEutLR5XZ6I9ODMhRbWfVjFb6lJWEQlfLh3mFEwlH+7bz5rv3IdU0Zn83ev7WHRt8v40btH\naGpVyIvEq1d2HFeTsChImnDvMO+K4bzw+wv4yR8sYNyIQfzVf37E0u9sZHX5x7S0tXtdnoh0U1ru\nZ+robGaqSVhEJV24d7h20khK//Banv+9+eRk9+fP1u7i5sc38vNtlbS1O6/LExFg74kz7KisZ3lJ\noZqERVjShjuAmbGwOJeX/ug6vn9vCYP7ZfBw6Q4+9cQmXt15nHaFvIinSssr1SQsSpI63DuYGTdP\nG8WrX72BZ357LgY88OMPWPbkZt746ASB3mciEkuBJmGV3DJtFCMG9/O6nKSTEuHeIS3NuH1GPv/1\n0EK+e89sLrS0sfJHW7nr6V9Qtq9aIS8SQ2/tOckn51p0ITVKUircO6SnGXfNHstbDy/isbtnUtvQ\nzH3/Vs7dz77LLytOeV2eSEoo9fnJHzqAG9UkLCpSMtw7ZKSnsaKkkLI/WczffeYqjn1yni99fwv3\nrHqX8iN1XpcnkrSq6s+zSU3Coiqlw71Dv4w0fmfBFWz408V8445pVFQ3svzZd7n3uffZ4T/tdXki\nSWft1mCTsHlakokWhXsXAzLT+b0bJrDp0cX8xe1T2VV5mrue/gW//0Mfu4+f8bo8kaQQaBJWybUT\nRzJu5CCvy0laCvcQBvXL4A8XTWLzny3lkVuK2XK4lmVPbub+F7Zx4ORZr8sTSWhbDtfxcZ2ahEWb\nwv0Ssvpn8NWbinjn0aV8delkNuyr5tYnNvG11ds5cqrR6/JEElKpz0/2gAxuu2q016UkNYV7GIYO\nyuSRW6ew+c+WsnLhRF7/sIqbHt/Ioz/bgb/unNfliSSMMxdaWLerirtmj2FAppqERZPCvRdGDO7H\nX9x+JZseXcK9117BS9uPs/SfNvC/X9rFifoLXpcnEvde3n6cplY1CYsFhXsf5GUP4Jt3Tmfjny5m\nRUkhq8v9LPx2GX/7ym5qzurWfyIXU+oLNAmbMVZNwqItrHA3s9vMbJ+ZVZjZn4d4fbGZ1ZvZ9uDX\nNyJfavzJHzqQb312BusfWcxds8bww3ePsPCxMv7h9T180qhb/4l0tafqDDsr61mhJmEx0WO4m1k6\n8DRwOzAN+KKZTQsxdLNzbnbw628jXGdcKxwxiG8vn8WbX1vIrdNHsWrTIW58rIzH39hH/Xnd+k8E\nAmft/dLT1CQsRsI5c58PVDjnDjnnmoGfAndFt6zENDE3i+/eM4f/fmghC4tzeHJ9BTf+43qeWn+A\nhibd+k9SV1NrGy99cIxbpo1iuJqExUQ44T4W8Hf5vjL4XHfXmdlOM3vdzKZHpLoEVTwqm3/57Xm8\n9sc3MH/CCL7zxn4WPlbGqk0HOd+su0JJ6nlrd3WgSZj2tsdMpC6obgPGOedmAt8DXgo1yMxWmpnP\nzHw1NTUROnT8mj5mKN//H1fz0v3XM33MEP5+3V4WfruMf/vFYd3fVVJKqc/PmKEDuGFyjtelpIxw\nwv0Y0PWf24Lgc52cc2eccw3Bx+uATDP7jd9F59wq51yJc64kNzd1OsHNLhzGj/7XNaz58rVMzBnM\n37yymyXf2cALW47S3Kpb/0lyO376PJsOqElYrGWEMaYcKDKzCQRC/R7gS10HmNlo4KRzzpnZfAL/\naNRGuthEd/X4Efx05QJ+ebCWf3pjH3/54oc8s+EgD95UxGfnjCUjXTtTvdDc2s6R2kYOnGxg/8mz\n+OvOMW3MEBZPyWNS7mDt7LhMa7dW4hws1972mLJwblBhZsuAJ4B04Dnn3LfM7MsAzrlnzewB4CtA\nK3AeeNg598tLvWdJSYnz+XyXW3/Ccs6xYX8Nj7+xn13H6pmYM5gHby7ijpljdHYTJS1t7Rw51cj+\nYIhXVAd+PHyqkdbgLRfNICerf+fnFQqGD2TJlDwWT8nl2kkjGdQvnPMh6dDe7lj0nTIKhw/ix3+w\nwOtykoKZbXXOlfQ4zqu7D6V6uHdwzvHG7pP885v72XviLMWjsvjazcV8avpo0hTyfdIR4geC4d1x\nRt49xMeNGERRXjbFo7IoHpXN5LwsJudlMSAzncpPzrFhXw0b9tXwi4pTnG9po19GGtdMGMHiKXks\nmZLLhByd1ffklwdP8aX/t4Xv3jObu2ZrC2QkKNwTTHu747VdVfzzW/s5VNPItPwhPHJrMUun5ilA\nLqKlrZ2jtb86Ez9Q3cCBYIi3tHUP8SyKRgWCvCgvm0m5WQzsF15vk6bWNsoPf0LZvmo27KvmYE2g\nady4EYNYMiWXxVPyWDBxZNjvl0oe+ukHvL23mvK/vFm9ZCJE4Z6gWtva+c/tx/nu2wf4uO4cswuH\n8fAtxdxYlJOyIR8I8XMcOHk2EOTVZ0OGeOHwQYHwHpVNUV7gbLw3IR4uf905NuyrDpzVHzzFhZZ2\n+meksWDiyM6wH58zOKLHTET151uY/623WFFSyP/5zFVel5M0FO4JrqWtnbVbK3ny7QMcr7/A/PEj\neOTWYq6ZONLr0qKmta2dI8EQ77qkcuhUQ2eIAxSOGEhxXvavnYlPzot8iIfjQksb7x+uo2xfNRv3\n1XAo2Ap6Qs5gFhXnsmRqHtdMGJGSZ60/eu8of/XSh7zywA3MKFAvmUhRuCeJptY2Vpf7eWp9BdVn\nm7hhcg4P31rM3HHDvS6tz1rb2jla1+VMPHhx81BNI81tv9oa2hHik0dlUZyXHTgTzxsc1xc1j9Y2\nsmFfDWX7qnn3YC1Nre0MyEzjukk5LJ6Sy+LivJS5+9Cd33uH1nbHuj++IWX/1xkNCvckc6Gljf94\n7yjPbDhIbWMzS6fm8fAtxVwVx931uob4gZMN7A+uiXcP8YLhAykelU1RMMSLRgUubMZziIfjQksb\n7x6qZWMw7I/WBnr/T8wdzOLiPJZMzWX+hBH0z0i+s/rdx8+w7MnNfPPOadx3/QSvy0kqCvck1djU\nyg/fPcK/bjxE/fkWPjV9FF+7pZipo4d4VlNrWzsf151j/8lAeF8qxDvWwjuWVCblZjG4f2KHeLgO\nn2qkbG81G/bX8N6hWppb2xmYmc71k0eyaEoei4tzKRyRHGf1f/3yR/x4y8ds+fpN6iUTYQr3JHfm\nQgvPvXOYH2w+TENzK3fMHMNDNxcxKTcrasdsa3edu1Mqqn+1pHLoVOOvfdJ27LCBv7a9sOPHVAnx\ncJxvbuPdQ6c6l3D8decBmJyX1XlR9urxI+iXkXgfbGtqbeOav3+b6yfn8PSX5npdTtJRuKeI0+ea\nWbXpEP/+yyNcaGnjs3MKePCmosta121rd8Ez8bOd6+IHqhs4WNPwGyFeFAzxjq2Gk/OyyFKI94pz\njkPBs/qN+2vYcqiO5rZ2BvdL57rJOZ0fohozbKDXpYbl1Z3HeeDHH/D8781nYXHqtBmJFYV7ijnV\n0MS/bjzI8+8epa3dsbykgAeWFjH2EoHQNcQ7Pq25/+TFQ/xXe8UV4tHU2NTKuwdrg/vqazh2OnBW\nP2VUduCi7JQ8SsYPJzNO21Xc+9z7HKxuYNOjS/Rp6yhQuKeok2cu8C9lFfzk/UCX5i/OL+TLiyfR\n1NLe+UGfji2GB2saaOoS4mOGDvjV9sIuZ+MKce8456iobuhcvik/UkdLmyOrfwbXTx4ZPKvPY/TQ\nAV6XCsCx0+e54R/X89WlRTx8S7HX5SQlhXuKO3b6PE+tP0Cpr5K29l//PR4zdACTR2VT3HlxM7A7\nJXtApkfVSrgamlr5RUVgrX7jvmqOB2/MPnV0dmdbhLlXeHdW/+TbB3j8zf1sfnRJ0lwcjjcKdwEC\n+65f3n6cvCH9O8/GFeLJwTnH/pMNbNhXTdm+anxHPqG13ZHdP4Mbi3NYXJzHoim5jBoSm7P69nbH\nwm+XccXIQbzw+2oSFi3hhrv+v53krhg5mK/eVOR1GRIFZsaU0dlMGZ3NHy6axNkLLZ1n9WX7qlm3\n6wQA0/KHsGRqYK1+TuGwqLWWfu9QLZWfnOdPPzUlKu8vvaNwF0kS2QMyue2qfG67Kh/nHHtPnO0M\n+mc3HuLpsoMMGZDBjcW5LJmSx6LiXHKz+0fs+Kt9foYMyOBT00dH7D2l7xTuIknIzLgyfwhX5g/h\nK4snUX++46w+sAPntZ1VAFw1dkjnVsvZhcP7vLul/lwLr394gnuuLkzJPjrxSOEukgKGDsxk2Yx8\nls0InNXvrjoT7FdfzdNlFXxvfQXDBmVyY1EuS6bksrA4l5ys8M/qX95xjObWdlbobktxQ+EukmLM\njOljhjJ9zFDuXzKZ+nMtbK6ooWxvDRv31/DKjuOYwcyxQ1kU3IEzs2DYJc/qV/v8TMsfEte9jlKN\nwl0kxQ0dlMkdM8dwx8wxtLc7Pjp+pnMHzlPrD/Dk2wcYPiiTRcWBi7ILi3MZ0aVfzEfH6/nw2Bn+\n+s5pHv4qpDuFu4h0SkszZhQMZUbBUL56UxGfNDazueIUG4KtEV7aHjirn1UwrHOtfu22Svqlp/GZ\nObqNXjzRPncRCUt7u2PXsfrOHTg7Kk/TER93zMznKTUJiwntcxeRiEpLM2YVDmNW4TAevLmIusZm\nNu2vofxIHf/zuvFelyfdKNxFpE9GDO7HZ+aM1XJMnIrPtnIiInJZFO4iIkkorHA3s9vMbJ+ZVZjZ\nn4d43czsyeDrO81MV1ZERDzUY7ibWTrwNHA7MA34opl139B6O1AU/FoJPBPhOkVEpBfCOXOfD1Q4\n5w4555qBnwJ3dRtzF/C8C3gPGGZm+RGuVUREwhROuI8F/F2+rww+19sxmNlKM/OZma+mpqa3tYqI\nSJhiekHVObfKOVfinCvJzdWNc0VEoiWccD8GdG31VhB8rrdjREQkRnpsP2BmGcB+4CYCgV0OfMk5\n91GXMZ8GHgCWAdcATzrn5vfwvjXA0T7WnQOc6uPPjaZ4rQvitzbV1Tuqq3eSsa4rnHM9Ln30+AlV\n51yrmT0A/DeQDjznnPvIzL4cfP1ZYB2BYK8AzgH3hfG+fV6XMTNfOL0VYi1e64L4rU119Y7q6p1U\nrius9gPOuXUEArzrc892eeyA+yNbmoiI9JU+oSoikoQSNdxXeV3ARcRrXRC/tamu3lFdvZOydXnW\nz11ERKInUc/cRUTkEuI63OO1YVkYdS02s3oz2x78+kaM6nrOzKrN7MOLvO7VfPVUV8zny8wKzazM\nzHab2Udm9mCIMTGfrzDr8mK+BpjZ+2a2I1jX34QY48V8hVOXJ38fg8dON7MPzOzVEK9Fd76cc3H5\nRWDb5UE/2XOyAAACqUlEQVRgItAP2AFM6zZmGfA6YMACYEuc1LUYeNWDOVsIzAU+vMjrMZ+vMOuK\n+XwB+cDc4ONsAp/liIc/X+HU5cV8GZAVfJwJbAEWxMF8hVOXJ38fg8d+GPhxqONHe77i+cw9XhuW\nhVOXJ5xzm4C6SwzxpMFbGHXFnHOuyjm3Lfj4LLCH3+yHFPP5CrOumAvOQUPw28zgV/cLdl7MVzh1\necLMCoBPA9+/yJCozlc8h3vEGpZ5UBfAdcH/ar1uZtOjXFO4vJivcHk2X2Y2HphD4KyvK0/n6xJ1\ngQfzFVxi2A5UA2865+JivsKoC7z58/UE8CjQfpHXozpf8RzuiWwbMM45NxP4HvCSx/XEO8/my8yy\ngLXAQ865M7E6bk96qMuT+XLOtTnnZhPoHTXfzK6KxXF7EkZdMZ8vM7sDqHbObY32sS4mnsM9XhuW\n9XhM59yZjv8qusCnezPNLCfKdYUjLhu8eTVfZpZJIEBfcM79PMQQT+arp7q8/vPlnDsNlAG3dXvJ\n0z9fF6vLo/m6HvgtMztCYOl2qZn9R7cxUZ2veA73cqDIzCaYWT/gHuDlbmNeBu4NXnVeANQ756q8\nrsvMRpuZBR/PJzDPtVGuKxxezFePvJiv4PF+AOxxzj1+kWExn69w6vJovnLNbFjw8UDgFmBvt2Fe\nzFePdXkxX865v3DOFTjnxhPIiPXOud/pNiyq8xVWbxkvuCg1LItRXXcDXzGzVuA8cI8LXh6PJjP7\nCYGdATlmVgl8k8AFJs/mK8y6vJiv64HfBXYF12sBvg6M61KXF/MVTl1ezFc+8EML3HYzDSh1zr3q\n9d/HMOvy5O9jKLGcL31CVUQkCcXzsoyIiPSRwl1EJAkp3EVEkpDCXUQkCSncRUSSkMJdRCQJKdxF\nRJKQwl1EJAn9f1ANeSnHRgZUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69160d7908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 3.02 s, total: 36.8 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Change last layer to output 10 classes since our dataset has 10 classes\n",
    "model.fc = nn.Linear(model.fc.in_features,10)# Complete this statement. It is similar to the resnet18 case\n",
    "model.cuda()\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr = learning_rate) \n",
    "\n",
    "\n",
    "def train():\n",
    "    # Code for training the model\n",
    "    # Make sure to output a matplotlib graph of training losses\n",
    "    \n",
    "    loss_epoch = np.array([])\n",
    "    for epoch in range(num_epochs):        \n",
    "        \n",
    "        model.train()        \n",
    "        for i, (input1,target) in enumerate(train_loader):\n",
    "            \n",
    "            input_var = torch.autograd.Variable(input1).cuda()            \n",
    "            target = target.cuda(async = True)\n",
    "            target_var = torch.autograd.Variable(target)\n",
    "            \n",
    "            output = model(input_var)            \n",
    "            loss = criterion(output, target_var)           \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "            \n",
    "        loss_epoch = np.concatenate((loss_epoch,loss.cpu().data.numpy()))\n",
    "    \n",
    "    plt.plot(loss_epoch)\n",
    "    plt.show()\n",
    "    \n",
    "%time train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.1443850267\n",
      "CPU times: user 1.23 s, sys: 136 ms, total: 1.37 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # Write loops for testing the model on the test set\n",
    "    # You should also print out the accuracy of the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (input1,target) in enumerate(test_loader):\n",
    "            \n",
    "            input_var = torch.autograd.Variable(input1,volatile = True).cuda()\n",
    "            \n",
    "            target = target.cuda(async = True)\n",
    "            target_var = torch.autograd.Variable(target)\n",
    "                        \n",
    "            output = model(input_var)\n",
    "            output = output.float()\n",
    "            \n",
    "            t1 = output.max(1)[1].cpu().data.numpy()\n",
    "            t2 = target_var.cpu().data.numpy()\n",
    "            correct += sum(t1==t2)\n",
    "            total += len(t2)\n",
    "            \n",
    "    print('Accuracy: '+ str(correct*100.0/total))\n",
    "%time test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training from scratch\n",
    "Now we shall try training the model from scratch and observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reinstantiate the model and optimizer\n",
    "model = CustomResnet(num_classes = 10)\n",
    "model.cuda()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "optimizer_fromScratch = torch.optim.Adam(model.parameters(), lr = learning_rate) \n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# Train\n",
    "%time train()\n",
    "\n",
    "# Test\n",
    "%time test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of Assignment 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
