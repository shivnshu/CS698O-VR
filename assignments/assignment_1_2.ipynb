{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Networks\n",
    "In this notebook you have to create a custom network whose architecture has been given, and use the dataset you created earlier to train and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "#\n",
    "# Several of the imports you will need have been added but you will need to provide the\n",
    "# rest yourself; you should be able to figure out most of the imports as you go through\n",
    "# the notebook since without proper imports your code will fail to run\n",
    "#\n",
    "# All import statements go in this block\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All hyper parameters go in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Dataset and Loader\n",
    "This is the same as part 1. Simply use the same code to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset):\n",
    "    # Copy the code from part 1\n",
    "    \n",
    "composed_transform = transforms.Compose([transforms.Scale((32,32)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Network\n",
    "It's time to create a new custom network. This network is based on Resnet (indeed it is a resnet since it uses skip connections). The architecture of the network is provided in the diagram. It specifies the layer names, layer types as well as their parameters.\n",
    "<img src=\"architecture.png\" width=100>\n",
    "[Full size image](architecture.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomResnet(nn.Module): # Extend PyTorch's Module class\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(CustomResnet, self).__init__() # Must call super __init__()\n",
    "        \n",
    "        # Define the layers of the network here\n",
    "        # There should be 17 total layers as evident from the diagram\n",
    "        # The parameters and names for the layers are provided in the diagram\n",
    "        # The variable names have to be the same as the ones in the diagram\n",
    "        # Otherwise, the weights will not load\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here you have to define the forward pass\n",
    "        # Make sure you take care of the skip connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune on pre-trained CIFAR-100 weights\n",
    "We shall now finetune our model using pretrained CIFAR-100 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CustomResnet(num_classes = 100) # 100 classes since CIFAR-100 has 100 classes\n",
    "\n",
    "# Load CIFAR-100 weights. (Download them from assignment page)\n",
    "# If network was properly implemented, weights should load without any problems\n",
    "model.load_state_dict(torch.load('')) # Supply the path to the weight file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional\n",
    "As a sanity check you may load the CIFAR-100 test dataset and test the above model. You should get an accuracy of ~41%. This part is optional and is meant for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Block for optionally running the model on CIFAR-100 test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finetune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change last layer to output 10 classes since our dataset has 10 classes\n",
    "model.fc = # Complete this statement. It is similar to the resnet18 case\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = # Define cross-entropy loss\n",
    "optimizer = # Use Adam optimizer, use learning_rate hyper parameter\n",
    "\n",
    "def train():\n",
    "    # Code for training the model\n",
    "    # Make sure to output a matplotlib graph of training losses\n",
    "\n",
    "%time train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Write loops for testing the model on the test set\n",
    "    # You should also print out the accuracy of the model\n",
    "    \n",
    "%time test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training from scratch\n",
    "Now we shall try training the model from scratch and observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reinstantiate the model and optimizer\n",
    "model = CustomResnet(num_classes = 10)\n",
    "optimizer = # Use Adam optimizer, use learning_rate hyper parameter\n",
    "\n",
    "# Train\n",
    "%time train()\n",
    "\n",
    "# Test\n",
    "%time test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of Assignment 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
